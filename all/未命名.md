```mermaid
# 定义要爬取的url连接
url_list = ['https://top.baidu.com/board?tab=teleplay', 'https://top.baidu.com/board?tab=movie']

# 设置请求头信息
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
}

# 获取电影名称列表
movie_names = []

# 获取页面数据
for url in url_list:
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        soup = BeautifulSoup(response.text, "lxml")
        name_list = [x.get_text().strip() for x in soup.select('.title_dIF3B')]
        movie_names.extend(name_list)

print(movie_names)

# 百度百科搜索函数
def search_baike(query):
    base_url = "https://baike.baidu.com/search/word"
    params = {
        'word': query
    }
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50',
    }
    response = requests.get(base_url, params=params, headers=headers)

    soup = BeautifulSoup(response.text, 'html.parser')
    summary_div = soup.find('div', class_='lemmaSummary_kzr82 J-summary')
    if summary_div:
        summary_text = summary_div.get_text(strip=True)
        cleaned_text = re.sub(r'\[\d+\]', '', summary_text)
        print(cleaned_text)
        return cleaned_text
    return None
  
```